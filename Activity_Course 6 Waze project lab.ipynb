{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze Project**\n",
    "**Course 6 - The nuts and bolts of machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfCZ5KuI_2lT"
   },
   "source": [
    "Your team is close to completing their user churn project. Previously, you completed a project proposal, and used Python to explore and analyze Waze’s user data, create data visualizations, and conduct a hypothesis test. Most recently, you built a binomial logistic regression model based on multiple variables.\n",
    "\n",
    "Leadership appreciates all your hard work. Now, they want your team to build a machine learning model to predict user churn. To get the best results, your team decides to build and test two tree-based models: random forest and XGBoost.\n",
    "\n",
    "Your work will help leadership make informed business decisions to prevent user churn, improve user retention, and grow Waze’s business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 6 End-of-Course Project: Build a machine learning model**\n",
    "\n",
    "In this activity, you will practice using tree-based modeling techniques to predict on a binary target class.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this model is to find factors that drive user churn.\n",
    "\n",
    "**The goal** of this model is to predict whether or not a Waze user is retained or churned.\n",
    "<br/>\n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Ethical considerations\n",
    "* Consider the ethical implications of the request\n",
    "\n",
    "* Should the objective of the model be adjusted?\n",
    "\n",
    "**Part 2:** Feature engineering\n",
    "\n",
    "* Perform feature selection, extraction, and transformation to prepare the data for modeling\n",
    "\n",
    "**Part 3:** Modeling\n",
    "\n",
    "* Build the models, evaluate them, and advise on next steps\n",
    "\n",
    "Follow the instructions and answer the questions below to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.\n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsrI9g32nrAs"
   },
   "source": [
    "# **Build a machine learning model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzDjfCSLf6Jq"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8kJRDEKn4A-"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5g1A74r0ow_"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n",
    "\n",
    "In this stage, consider the following questions:\n",
    "\n",
    "1.   What are you being asked to do?\n",
    "\n",
    "\n",
    "2.   What are the ethical implications of the model? What are the consequences of your model making errors?\n",
    "  *   What is the likely effect of the model when it predicts a false negative (i.e., when the model says a Waze user won't churn, but they actually will)?\n",
    "  *   What is the likely effect of the model when it predicts a false positive (i.e., when the model says a Waze user will churn, but they actually won't)?\n",
    "\n",
    "3.  Do the benefits of such a model outweigh the potential problems?\n",
    "4.  Would you proceed with the request to build this model? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y755T4Q18iwC"
   },
   "source": [
    "1. Build random forest and XGBoost machine learning models to predict if a user will churn or be retained.\n",
    "2. If the model predicts a false negative, likely Waze lose a coustermer they potentially could have retained with incentavies. If the model predicts a false positive, likeley Waze will lose money giving incentives to customers who we not likely to churn.\n",
    "3. I believe the benefits outweigh the potential problems. Further analysis is required on the effectiveness of the marketing incentives and the cost of user churn.\n",
    "4. Yes, there aren't any significant risks for building this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### **Task 1. Imports and data loading**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import packages for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import packages for data modeling\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# This module lets us save our models once we fit them.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeXTZ2tdbALL"
   },
   "source": [
    "Now read in the dataset as `df0` and inspect the first five rows.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df0 = pd.read_csv('waze_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1HyORSaQo_LU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \n",
       "0              1985.775061             28            19  Android  \n",
       "1              3160.472914             13            11   iPhone  \n",
       "2              1610.735904             14             8  Android  \n",
       "3               587.196542              7             3   iPhone  \n",
       "4              1219.555924             27            18  Android  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first five rows\n",
    "### YOUR CODE HERE ###\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgPRBjizg1oo"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "### **Task 2. Feature engineering**\n",
    "\n",
    "You have already prepared much of this data and performed exploratory data analysis (EDA) in previous courses. You know that some features had stronger correlations with churn than others, and you also created some features that may be useful.\n",
    "\n",
    "In this part of the project, you'll engineer these features and some new features to use for modeling.\n",
    "\n",
    "To begin, create a copy of `df0` to preserve the original dataframe. Call the copy `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [],
   "source": [
    "# Copy the df0 dataframe\n",
    "### YOUR CODE HERE ###\n",
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTgC9H_tt-G2"
   },
   "source": [
    "Call `info()` on the new dataframe so the existing columns can be easily referenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "teUeCF-yf_6o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPtJEHjcuepR"
   },
   "source": [
    "#### **`km_per_driving_day`**\n",
    "\n",
    "1. Create a feature representing the mean number of kilometers driven on each driving day in the last month for each user. Add this feature as a column to `df`.\n",
    "\n",
    "2. Get descriptive statistics for this new feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vAB6cv6xfvZn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>1.499900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.022063e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.672804e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.231459e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.579257e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \n",
       "count   14999.000000  14999.000000        1.499900e+04  \n",
       "mean       15.537102     12.179879                 inf  \n",
       "std         9.004655      7.824036                 NaN  \n",
       "min         0.000000      0.000000        3.022063e+00  \n",
       "25%         8.000000      5.000000        1.672804e+02  \n",
       "50%        16.000000     12.000000        3.231459e+02  \n",
       "75%        23.000000     19.000000        7.579257e+02  \n",
       "max        31.000000     30.000000                 inf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `km_per_driving_day` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n",
    "# 2. Get descriptive stats\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSqM4oiyuuzw"
   },
   "source": [
    "Notice that some values are infinite. This is the result of there being values of zero in the `driving_days` column. Pandas imputes a value of infinity in the corresponding rows of the new column because division by zero is undefined.\n",
    "\n",
    "1. Convert these values from infinity to zero. You can use `np.inf` to refer to a value of infinity.\n",
    "\n",
    "2. Call `describe()` on the `km_per_driving_day` column to verify that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vv3owriWuuDQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>578.963113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>1030.094384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.238895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>272.889272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>558.686918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15420.234110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \n",
       "count   14999.000000  14999.000000        14999.000000  \n",
       "mean       15.537102     12.179879          578.963113  \n",
       "std         9.004655      7.824036         1030.094384  \n",
       "min         0.000000      0.000000            0.000000  \n",
       "25%         8.000000      5.000000          136.238895  \n",
       "50%        16.000000     12.000000          272.889272  \n",
       "75%        23.000000     19.000000          558.686918  \n",
       "max        31.000000     30.000000        15420.234110  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "### YOUR CODE HERE ###\n",
    "df = df.replace(np.inf,0)\n",
    "# 2. Confirm that it worked\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "#### **`percent_sessions_in_last_month`**\n",
    "\n",
    "1. Create a new column `percent_sessions_in_last_month` that represents the percentage of each user's total sessions that were logged in their last month of use.\n",
    "\n",
    "2. Get descriptive statistics for this new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>578.963113</td>\n",
       "      <td>0.170248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>1030.094384</td>\n",
       "      <td>0.878330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.238895</td>\n",
       "      <td>0.040436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>272.889272</td>\n",
       "      <td>0.088712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>558.686918</td>\n",
       "      <td>0.174975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15420.234110</td>\n",
       "      <td>90.822008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \\\n",
       "count   14999.000000  14999.000000        14999.000000   \n",
       "mean       15.537102     12.179879          578.963113   \n",
       "std         9.004655      7.824036         1030.094384   \n",
       "min         0.000000      0.000000            0.000000   \n",
       "25%         8.000000      5.000000          136.238895   \n",
       "50%        16.000000     12.000000          272.889272   \n",
       "75%        23.000000     19.000000          558.686918   \n",
       "max        31.000000     30.000000        15420.234110   \n",
       "\n",
       "       percent_sessions_in_last_month  \n",
       "count                    14999.000000  \n",
       "mean                         0.170248  \n",
       "std                          0.878330  \n",
       "min                          0.000000  \n",
       "25%                          0.040436  \n",
       "50%                          0.088712  \n",
       "75%                          0.174975  \n",
       "max                         90.822008  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `percent_sessions_in_last_month` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['percent_sessions_in_last_month'] = df['activity_days'] / df['total_sessions']\n",
    "# 1. Get descriptive stats\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgkLrOf_OrE"
   },
   "source": [
    "#### **`professional_driver`**\n",
    "\n",
    "Create a new, binary feature called `professional_driver` that is a 1 for users who had 60 or more drives <u>**and**</u> drove on 15+ days in the last month.\n",
    "\n",
    "**Note:** The objective is to create a new feature that separates professional drivers from other drivers. In this scenario, domain knowledge and intuition are used to determine these deciding thresholds, but ultimately they are arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5UK5jR6U9t1"
   },
   "source": [
    "To create this column, use the [`np.where()`](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function. This function accepts as arguments:\n",
    "1. A condition\n",
    "2. What to return when the condition is true\n",
    "3. What to return when the condition is false\n",
    "\n",
    "```\n",
    "Example:\n",
    "x = [1, 2, 3]\n",
    "x = np.where(x > 2, 100, 0)\n",
    "x\n",
    "array([  0,   0, 100])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dQdMgikKU-5T"
   },
   "outputs": [],
   "source": [
    "# Create `professional_driver` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['professional_driver'] = np.where(((df['drives']>=60) & (df['activity_days']>=15)),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3bWzofHVIuC"
   },
   "source": [
    "#### **`total_sessions_per_day`**\n",
    "\n",
    "Now, create a new column that represents the mean number of sessions per day _since onboarding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bWXPMPHSVJQd"
   },
   "outputs": [],
   "source": [
    "# Create `total_sessions_per_day` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['total_sessions_per_day'] =df['total_sessions'] / df['n_days_after_onboarding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HLX7SwJVJlO"
   },
   "source": [
    "As with other features, get descriptive statistics for this new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h1DFSMNSVKEg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "      <th>professional_driver</th>\n",
       "      <th>total_sessions_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>578.963113</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.226748</td>\n",
       "      <td>0.338698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>1030.094384</td>\n",
       "      <td>0.878330</td>\n",
       "      <td>0.418742</td>\n",
       "      <td>1.314333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.238895</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>272.889272</td>\n",
       "      <td>0.088712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>558.686918</td>\n",
       "      <td>0.174975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15420.234110</td>\n",
       "      <td>90.822008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.763874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \\\n",
       "count   14999.000000  14999.000000        14999.000000   \n",
       "mean       15.537102     12.179879          578.963113   \n",
       "std         9.004655      7.824036         1030.094384   \n",
       "min         0.000000      0.000000            0.000000   \n",
       "25%         8.000000      5.000000          136.238895   \n",
       "50%        16.000000     12.000000          272.889272   \n",
       "75%        23.000000     19.000000          558.686918   \n",
       "max        31.000000     30.000000        15420.234110   \n",
       "\n",
       "       percent_sessions_in_last_month  professional_driver  \\\n",
       "count                    14999.000000         14999.000000   \n",
       "mean                         0.170248             0.226748   \n",
       "std                          0.878330             0.418742   \n",
       "min                          0.000000             0.000000   \n",
       "25%                          0.040436             0.000000   \n",
       "50%                          0.088712             0.000000   \n",
       "75%                          0.174975             0.000000   \n",
       "max                         90.822008             1.000000   \n",
       "\n",
       "       total_sessions_per_day  \n",
       "count            14999.000000  \n",
       "mean                 0.338698  \n",
       "std                  1.314333  \n",
       "min                  0.000298  \n",
       "25%                  0.051037  \n",
       "50%                  0.100775  \n",
       "75%                  0.216269  \n",
       "max                 39.763874  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive stats\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6sCAgOoVZM7"
   },
   "source": [
    "#### **`km_per_hour`**\n",
    "\n",
    "Create a column representing the mean kilometers per hour driven in the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Zu142H3aVc3o"
   },
   "outputs": [],
   "source": [
    "# Create `km_per_hour` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['km_per_hour'] =  df['driven_km_drives'] / (df['duration_minutes_drives']/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d6N9jf8ViW-"
   },
   "source": [
    "#### **`km_per_drive`**\n",
    "\n",
    "Create a column representing the mean number of kilometers per drive made in the last month for each user. Then, print descriptive statistics for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v5R5-MteVlMB"
   },
   "outputs": [],
   "source": [
    "# Create `km_per_drive` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['driving_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txY8qR1LVlq1"
   },
   "source": [
    "This feature has infinite values too. Convert the infinite values to zero, then confirm that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PZrHMuPuVmIt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "      <th>professional_driver</th>\n",
       "      <th>total_sessions_per_day</th>\n",
       "      <th>km_per_hour</th>\n",
       "      <th>km_per_drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>578.963113</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.226748</td>\n",
       "      <td>0.338698</td>\n",
       "      <td>190.394608</td>\n",
       "      <td>578.963113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>1030.094384</td>\n",
       "      <td>0.878330</td>\n",
       "      <td>0.418742</td>\n",
       "      <td>1.314333</td>\n",
       "      <td>334.674026</td>\n",
       "      <td>1030.094384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>72.013095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.238895</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>90.706222</td>\n",
       "      <td>136.238895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>272.889272</td>\n",
       "      <td>0.088712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>122.382022</td>\n",
       "      <td>272.889272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>558.686918</td>\n",
       "      <td>0.174975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216269</td>\n",
       "      <td>193.130119</td>\n",
       "      <td>558.686918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15420.234110</td>\n",
       "      <td>90.822008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.763874</td>\n",
       "      <td>23642.920871</td>\n",
       "      <td>15420.234110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \\\n",
       "count   14999.000000  14999.000000        14999.000000   \n",
       "mean       15.537102     12.179879          578.963113   \n",
       "std         9.004655      7.824036         1030.094384   \n",
       "min         0.000000      0.000000            0.000000   \n",
       "25%         8.000000      5.000000          136.238895   \n",
       "50%        16.000000     12.000000          272.889272   \n",
       "75%        23.000000     19.000000          558.686918   \n",
       "max        31.000000     30.000000        15420.234110   \n",
       "\n",
       "       percent_sessions_in_last_month  professional_driver  \\\n",
       "count                    14999.000000         14999.000000   \n",
       "mean                         0.170248             0.226748   \n",
       "std                          0.878330             0.418742   \n",
       "min                          0.000000             0.000000   \n",
       "25%                          0.040436             0.000000   \n",
       "50%                          0.088712             0.000000   \n",
       "75%                          0.174975             0.000000   \n",
       "max                         90.822008             1.000000   \n",
       "\n",
       "       total_sessions_per_day   km_per_hour  km_per_drive  \n",
       "count            14999.000000  14999.000000  14999.000000  \n",
       "mean                 0.338698    190.394608    578.963113  \n",
       "std                  1.314333    334.674026   1030.094384  \n",
       "min                  0.000298     72.013095      0.000000  \n",
       "25%                  0.051037     90.706222    136.238895  \n",
       "50%                  0.100775    122.382022    272.889272  \n",
       "75%                  0.216269    193.130119    558.686918  \n",
       "max                 39.763874  23642.920871  15420.234110  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "df = df.replace(np.inf,0)\n",
    "# 2. Confirm that it worked\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Sxs6agVunA"
   },
   "source": [
    "#### **`percent_of_sessions_to_favorite`**\n",
    "\n",
    "Finally, create a new column that represents the percentage of total sessions that were used to navigate to one of the users' favorite places. Then, print descriptive statistics for the new column.\n",
    "\n",
    "This is a proxy representation for the percent of overall drives that are to a favorite place. Since total drives since onboarding are not contained in this dataset, total sessions must serve as a reasonable approximation.\n",
    "\n",
    "People whose drives to non-favorite places make up a higher percentage of their total drives might be less likely to churn, since they're making more drives to less familiar places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vh22o46AVxd_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "      <th>professional_driver</th>\n",
       "      <th>total_sessions_per_day</th>\n",
       "      <th>km_per_hour</th>\n",
       "      <th>km_per_drive</th>\n",
       "      <th>percent_of_sessions_to_favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>80.633776</td>\n",
       "      <td>67.281152</td>\n",
       "      <td>189.964447</td>\n",
       "      <td>1749.837789</td>\n",
       "      <td>121.605974</td>\n",
       "      <td>29.672512</td>\n",
       "      <td>4039.340921</td>\n",
       "      <td>1860.976012</td>\n",
       "      <td>15.537102</td>\n",
       "      <td>12.179879</td>\n",
       "      <td>578.963113</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.226748</td>\n",
       "      <td>0.338698</td>\n",
       "      <td>190.394608</td>\n",
       "      <td>578.963113</td>\n",
       "      <td>1.665439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4329.982679</td>\n",
       "      <td>80.699065</td>\n",
       "      <td>65.913872</td>\n",
       "      <td>136.405128</td>\n",
       "      <td>1008.513876</td>\n",
       "      <td>148.121544</td>\n",
       "      <td>45.394651</td>\n",
       "      <td>2502.149334</td>\n",
       "      <td>1446.702288</td>\n",
       "      <td>9.004655</td>\n",
       "      <td>7.824036</td>\n",
       "      <td>1030.094384</td>\n",
       "      <td>0.878330</td>\n",
       "      <td>0.418742</td>\n",
       "      <td>1.314333</td>\n",
       "      <td>334.674026</td>\n",
       "      <td>1030.094384</td>\n",
       "      <td>8.865666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.441250</td>\n",
       "      <td>18.282082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>72.013095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3749.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>90.661156</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2212.600607</td>\n",
       "      <td>835.996260</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>136.238895</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>90.706222</td>\n",
       "      <td>136.238895</td>\n",
       "      <td>0.203471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7499.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>159.568115</td>\n",
       "      <td>1741.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3493.858085</td>\n",
       "      <td>1478.249859</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>272.889272</td>\n",
       "      <td>0.088712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>122.382022</td>\n",
       "      <td>272.889272</td>\n",
       "      <td>0.649818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11248.500000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>254.192341</td>\n",
       "      <td>2623.500000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5289.861262</td>\n",
       "      <td>2464.362632</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>558.686918</td>\n",
       "      <td>0.174975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216269</td>\n",
       "      <td>193.130119</td>\n",
       "      <td>558.686918</td>\n",
       "      <td>1.638526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14998.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>1216.154633</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>1236.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>21183.401890</td>\n",
       "      <td>15851.727160</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15420.234110</td>\n",
       "      <td>90.822008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.763874</td>\n",
       "      <td>23642.920871</td>\n",
       "      <td>15420.234110</td>\n",
       "      <td>777.563629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      sessions        drives  total_sessions  \\\n",
       "count  14999.000000  14999.000000  14999.000000    14999.000000   \n",
       "mean    7499.000000     80.633776     67.281152      189.964447   \n",
       "std     4329.982679     80.699065     65.913872      136.405128   \n",
       "min        0.000000      0.000000      0.000000        0.220211   \n",
       "25%     3749.500000     23.000000     20.000000       90.661156   \n",
       "50%     7499.000000     56.000000     48.000000      159.568115   \n",
       "75%    11248.500000    112.000000     93.000000      254.192341   \n",
       "max    14998.000000    743.000000    596.000000     1216.154633   \n",
       "\n",
       "       n_days_after_onboarding  total_navigations_fav1  \\\n",
       "count             14999.000000            14999.000000   \n",
       "mean               1749.837789              121.605974   \n",
       "std                1008.513876              148.121544   \n",
       "min                   4.000000                0.000000   \n",
       "25%                 878.000000                9.000000   \n",
       "50%                1741.000000               71.000000   \n",
       "75%                2623.500000              178.000000   \n",
       "max                3500.000000             1236.000000   \n",
       "\n",
       "       total_navigations_fav2  driven_km_drives  duration_minutes_drives  \\\n",
       "count            14999.000000      14999.000000             14999.000000   \n",
       "mean                29.672512       4039.340921              1860.976012   \n",
       "std                 45.394651       2502.149334              1446.702288   \n",
       "min                  0.000000         60.441250                18.282082   \n",
       "25%                  0.000000       2212.600607               835.996260   \n",
       "50%                  9.000000       3493.858085              1478.249859   \n",
       "75%                 43.000000       5289.861262              2464.362632   \n",
       "max                415.000000      21183.401890             15851.727160   \n",
       "\n",
       "       activity_days  driving_days  km_per_driving_day  \\\n",
       "count   14999.000000  14999.000000        14999.000000   \n",
       "mean       15.537102     12.179879          578.963113   \n",
       "std         9.004655      7.824036         1030.094384   \n",
       "min         0.000000      0.000000            0.000000   \n",
       "25%         8.000000      5.000000          136.238895   \n",
       "50%        16.000000     12.000000          272.889272   \n",
       "75%        23.000000     19.000000          558.686918   \n",
       "max        31.000000     30.000000        15420.234110   \n",
       "\n",
       "       percent_sessions_in_last_month  professional_driver  \\\n",
       "count                    14999.000000         14999.000000   \n",
       "mean                         0.170248             0.226748   \n",
       "std                          0.878330             0.418742   \n",
       "min                          0.000000             0.000000   \n",
       "25%                          0.040436             0.000000   \n",
       "50%                          0.088712             0.000000   \n",
       "75%                          0.174975             0.000000   \n",
       "max                         90.822008             1.000000   \n",
       "\n",
       "       total_sessions_per_day   km_per_hour  km_per_drive  \\\n",
       "count            14999.000000  14999.000000  14999.000000   \n",
       "mean                 0.338698    190.394608    578.963113   \n",
       "std                  1.314333    334.674026   1030.094384   \n",
       "min                  0.000298     72.013095      0.000000   \n",
       "25%                  0.051037     90.706222    136.238895   \n",
       "50%                  0.100775    122.382022    272.889272   \n",
       "75%                  0.216269    193.130119    558.686918   \n",
       "max                 39.763874  23642.920871  15420.234110   \n",
       "\n",
       "       percent_of_sessions_to_favorite  \n",
       "count                     14999.000000  \n",
       "mean                          1.665439  \n",
       "std                           8.865666  \n",
       "min                           0.000000  \n",
       "25%                           0.203471  \n",
       "50%                           0.649818  \n",
       "75%                           1.638526  \n",
       "max                         777.563629  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `percent_of_sessions_to_favorite` feature\n",
    "### YOUR CODE HERE ###\n",
    "df['percent_of_sessions_to_favorite'] = (df['total_navigations_fav1'] + df['total_navigations_fav2']) / df['total_sessions']\n",
    "# Get descriptive stats\n",
    "### YOUR CODE HERE ###\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZO0mvHRWGmF"
   },
   "source": [
    "### **Task 3. Drop missing values**\n",
    "\n",
    "Because you know from previous EDA that there is no evidence of a non-random cause of the 700 missing values in the `label` column, and because these observations comprise less than 5% of the data, use the `dropna()` method to drop the rows that are missing this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2TdA6SnGWJY-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14299, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "### YOUR CODE HERE ###\n",
    "df = df.dropna(axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du5kGt5CWJ4J"
   },
   "source": [
    "### **Task 4. Outliers**\n",
    "\n",
    "You know from previous EDA that many of these columns have outliers. However, tree-based models are resilient to outliers, so there is no need to make any imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxBYyXDSWPkw"
   },
   "source": [
    "### **Task 5. Variable encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57psLWIeaTk2"
   },
   "source": [
    "#### **Dummying features**\n",
    "\n",
    "In order to use `device` as an X variable, you will need to convert it to binary, since this variable is categorical.\n",
    "\n",
    "In cases where the data contains many categorical variables, you can use pandas built-in [`pd.get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html), or you can use scikit-learn's [`OneHotEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) function.\n",
    "\n",
    "**Note:** Each possible category of each feature will result in a feature for your model, which could lead to an inadequate ratio of features to observations and/or difficulty understanding your model's predictions.\n",
    "\n",
    "Because this dataset only has one remaining categorical feature (`device`), it's not necessary to use one of these special functions. You can just implement the transformation directly.\n",
    "\n",
    "Create a new, binary column called `device2` that encodes user devices as follows:\n",
    "\n",
    "* `Android` -> `0`\n",
    "* `iPhone` -> `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fntUcR4-aUfH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "      <th>professional_driver</th>\n",
       "      <th>total_sessions_per_day</th>\n",
       "      <th>km_per_hour</th>\n",
       "      <th>km_per_drive</th>\n",
       "      <th>percent_of_sessions_to_favorite</th>\n",
       "      <th>device2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "      <td>138.360267</td>\n",
       "      <td>0.094356</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130381</td>\n",
       "      <td>79.430298</td>\n",
       "      <td>138.360267</td>\n",
       "      <td>0.700931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1246.901868</td>\n",
       "      <td>0.039768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266854</td>\n",
       "      <td>260.389902</td>\n",
       "      <td>1246.901868</td>\n",
       "      <td>0.253903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "      <td>382.393602</td>\n",
       "      <td>0.103304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>113.953460</td>\n",
       "      <td>382.393602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>304.530374</td>\n",
       "      <td>0.103567</td>\n",
       "      <td>0</td>\n",
       "      <td>4.505948</td>\n",
       "      <td>93.351141</td>\n",
       "      <td>304.530374</td>\n",
       "      <td>4.867640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "      <td>219.455667</td>\n",
       "      <td>0.160478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>194.342970</td>\n",
       "      <td>219.455667</td>\n",
       "      <td>1.016363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \\\n",
       "0              1985.775061             28            19  Android   \n",
       "1              3160.472914             13            11   iPhone   \n",
       "2              1610.735904             14             8  Android   \n",
       "3               587.196542              7             3   iPhone   \n",
       "4              1219.555924             27            18  Android   \n",
       "\n",
       "   km_per_driving_day  percent_sessions_in_last_month  professional_driver  \\\n",
       "0          138.360267                        0.094356                    1   \n",
       "1         1246.901868                        0.039768                    0   \n",
       "2          382.393602                        0.103304                    0   \n",
       "3          304.530374                        0.103567                    0   \n",
       "4          219.455667                        0.160478                    1   \n",
       "\n",
       "   total_sessions_per_day  km_per_hour  km_per_drive  \\\n",
       "0                0.130381    79.430298    138.360267   \n",
       "1                0.266854   260.389902   1246.901868   \n",
       "2                0.051121   113.953460    382.393602   \n",
       "3                4.505948    93.351141    304.530374   \n",
       "4                0.107713   194.342970    219.455667   \n",
       "\n",
       "   percent_of_sessions_to_favorite  device2  \n",
       "0                         0.700931        0  \n",
       "1                         0.253903        1  \n",
       "2                         0.000000        0  \n",
       "3                         4.867640        1  \n",
       "4                         1.016363        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new `device2` variable\n",
    "### YOUR CODE HERE ###\n",
    "df['device2'] = np.where((df['device']=='iPhone'),1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgbEm7cOb6t8"
   },
   "source": [
    "#### **Target encoding**\n",
    "\n",
    "The target variable is also categorical, since a user is labeled as either \"churned\" or \"retained.\" Change the data type of the `label` column to be binary. This change is needed to train the models.\n",
    "\n",
    "Assign a `0` for all `retained` users.\n",
    "\n",
    "Assign a `1` for all `churned` users.\n",
    "\n",
    "Save this variable as `label2` so as not to overwrite the original `label` variable.\n",
    "\n",
    "**Note:** There are many ways to do this. Consider using `np.where()` as you did earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0jiVjplLb8W-"
   },
   "outputs": [],
   "source": [
    "# Create binary `label2` column\n",
    "### YOUR CODE HERE ###\n",
    "df['label2'] = np.where(df['label']=='churned', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD_zG59eaV2c"
   },
   "source": [
    "### **Task 6. Feature selection**\n",
    "\n",
    "Tree-based models can handle multicollinearity, so the only feature that can be cut is `ID`, since it doesn't contain any information relevant to churn.\n",
    "\n",
    "Note, however, that `device` won't be used simply because it's a copy of `device2`.\n",
    "\n",
    "Drop `ID` from the `df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kf3uGtUQaWSL"
   },
   "outputs": [],
   "source": [
    "# Drop `ID` column\n",
    "### YOUR CODE HERE ###\n",
    "df = df.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajj50RCCaXrF"
   },
   "source": [
    "### **Task 7. Evaluation metric**\n",
    "\n",
    "Before modeling, you must decide on an evaluation metric. This will depend on the class balance of the target variable and the use case of the model.\n",
    "\n",
    "First, examine the class balance of your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3JkjEYByaYbr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "retained    11763\n",
       "churned      2536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'label' col\n",
    "### YOUR CODE HERE ###\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9vnV1wtaZWJ"
   },
   "source": [
    "Approximately 18% of the users in this dataset churned. This is an unbalanced dataset, but not extremely so. It can be modeled without any class rebalancing.\n",
    "\n",
    "Now, consider which evaluation metric is best. Remember, accuracy might not be the best gauge of performance because a model can have high accuracy on an imbalanced dataset and still fail to predict the minority class.\n",
    "\n",
    "It was already determined that the risks involved in making a false positive prediction are minimal. No one stands to get hurt, lose money, or suffer any other significant consequence if they are predicted to churn. Therefore, select the model based on the recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n1eikFh8akS"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Construct stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 8. Modeling workflow and model selection process**\n",
    "\n",
    "The final modeling dataset contains 14,299 samples. This is towards the lower end of what might be considered sufficient to conduct a robust model selection process, but still doable.\n",
    "\n",
    "1. Split the data into train/validation/test sets (60/20/20)\n",
    "\n",
    "Note that, when deciding the split ratio and whether or not to use a validation set to select a champion model, consider both how many samples will be in each data partition, and how many examples of the minority class each would therefore contain. In this case, a 60/20/20 split would result in \\~2,860 samples in the validation set and the same number in the test set, of which \\~18%&mdash;or 515 samples&mdash;would represent users who churn.\n",
    "2. Fit models and tune hyperparameters on the training set\n",
    "3. Perform final model selection on the validation set\n",
    "4. Assess the champion model's performance on the test set\n",
    "\n",
    "![](https://raw.githubusercontent.com/adacert/tiktok/main/optimal_model_flow_numbered.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "### **Task 9. Split the data**\n",
    "\n",
    "Now you're ready to model. The only remaining step is to split the data into features/target variable and training/validation/test sets.\n",
    "\n",
    "1. Define a variable `X` that isolates the features. Remember not to use `device`.\n",
    "\n",
    "2. Define a variable `y` that isolates the target variable (`label2`).\n",
    "\n",
    "3. Split the data 80/20 into an interim training set and a test set. Don't forget to stratify the splits, and set the random state to 42.\n",
    "\n",
    "4. Split the interim training set 75/25 into a training set and a validation set, yielding a final ratio of 60/20/20 for training/validation/test sets. Again, don't forget to stratify the splits and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "# 1. Isolate X variables\n",
    "### YOUR CODE HERE ###\n",
    "X = df.drop(['label2', 'label', 'device'], axis=1)\n",
    "# 2. Isolate y variable\n",
    "### YOUR CODE HERE ###\n",
    "y = df['label2']\n",
    "# 3. Split into train and test sets\n",
    "### YOUR CODE HERE ###\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "# 4. Split into train and validate sets\n",
    "### YOUR CODE HERE ###\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moLls6Lech47"
   },
   "source": [
    "Verify the number of samples in the partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qWIog8v_ckIg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8579\n",
      "2860\n",
      "2860\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "for x in [X_train, X_val, X_test]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x-4vGANcki4"
   },
   "source": [
    "This aligns with expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vSaa0-xcu4Q"
   },
   "source": [
    "### **Task 10. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vynZs5het1b_"
   },
   "source": [
    "#### **Random forest**\n",
    "\n",
    "Begin with using `GridSearchCV` to tune a random forest model.\n",
    "\n",
    "1. Instantiate the random forest classifier `rf` and set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take.\n",
    " - `max_depth`\n",
    " - `max_features`\n",
    " - `max_samples`\n",
    " - `min_samples_leaf`\n",
    " - `min_samples_split`\n",
    " - `n_estimators`\n",
    "\n",
    "3. Define a dictionary `scoring` of scoring metrics for GridSearch to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `rf_cv`. Pass to it as arguments:\n",
    " - estimator=`rf`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit=_`)\n",
    "\n",
    " `refit` should be set to `'recall'`.<font/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvpX9RDFc2MD"
   },
   "source": [
    "**Note:** To save time, this exemplar doesn't use multiple values for each parameter in the grid search, but you should include a range of values in your search to home in on the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vj5rJWOv5O3d"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0],\n",
    "             'max_samples': [1.0],\n",
    "             'min_samples_leaf': [2],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [300],\n",
    "             }\n",
    "\n",
    "# 3. Define a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=4, refit='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_WvRA1RqTl"
   },
   "source": [
    "Now fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [1.0], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;recall&#x27;, scoring={&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [1.0], &#x27;min_samples_leaf&#x27;: [2],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;recall&#x27;, scoring={&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None], 'max_features': [1.0],\n",
       "                         'max_samples': [1.0], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [2], 'n_estimators': [300]},\n",
       "             refit='recall', scoring={'accuracy', 'precision', 'recall', 'f1'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHi_YJduQOH"
   },
   "source": [
    "Examine the best average score across all the validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13204171846940185"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "### YOUR CODE HERE ###\n",
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heGb51fHh3E5"
   },
   "source": [
    "Examine the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "kazNtYG4fQOI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best hyperparameter combo\n",
    "### YOUR CODE HERE ###\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZZnem5yiAau"
   },
   "source": [
    "Use the `make_results()` function to output all of the scores of your model. Note that the function accepts three arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeW48TS742jN"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To learn more about how this function accesses the cross-validation results, refer to the [`GridSearchCV` scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) for the `cv_results_` attribute.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "u-UodWEOedxz"
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "  # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                   'recall': 'mean_test_recall',\n",
    "                   'f1': 'mean_test_f1',\n",
    "                   'accuracy': 'mean_test_accuracy',\n",
    "                   }\n",
    "\n",
    "  # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "  # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "  # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "  # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'precision': [precision],\n",
    "                          'recall': [recall],\n",
    "                          'F1': [f1],\n",
    "                          'accuracy': [accuracy],\n",
    "                          },\n",
    "                         )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diQezudIfzHn"
   },
   "source": [
    "Pass the `GridSearch` object to the `make_results()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qAYb2QigiT_h"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest CV</td>\n",
       "      <td>0.480107</td>\n",
       "      <td>0.132042</td>\n",
       "      <td>0.206901</td>\n",
       "      <td>0.820841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  precision    recall        F1  accuracy\n",
       "0  Random Forest CV   0.480107  0.132042  0.206901  0.820841"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_results('Random Forest CV', rf_cv, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "Asside from the accuracy, the scores aren't that good. However, recall that when you built the logistic regression model in the last course the recall was \\~0.09, which means that this model has 33% better recall and about the same accuracy, and it was trained on less data.\n",
    "\n",
    "If you want, feel free to try retuning your hyperparameters to try to get a better score. You might be able to marginally improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOlktJ6l4Tgt"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    " Try to improve your scores using an XGBoost model.\n",
    "\n",
    "1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n",
    " - `max_depth`\n",
    " - `min_child_weight`\n",
    " - `learning_rate`\n",
    " - `n_estimators`\n",
    "\n",
    "3. Define a dictionary `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `xgb_cv`. Pass to it as arguments:\n",
    " - estimator=`xgb`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit='recall'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0ciO48nhiTqO"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [6, 12],\n",
    "             'min_child_weight': [3, 5],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# 3. Define a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y78-hQF9680x"
   },
   "source": [
    "Now fit the model to the `X_train` and `y_train` data.\n",
    "\n",
    "Note this cell might take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "dYCWs_HX6804"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxgb_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruQISDB76805"
   },
   "source": [
    "Get the best score from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UFLTmIDm6805"
   },
   "outputs": [],
   "source": [
    "# Examine best score\n",
    "xgb_cv.best_scoe_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwmWDuXZ6805"
   },
   "source": [
    "And the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "cdPUCuND6805"
   },
   "outputs": [],
   "source": [
    "# Examine best parameters\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8v8HTmQ7KdC"
   },
   "source": [
    "Use the `make_results()` function to output all of the scores of your model. Note that the function accepts three arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QL19dH2h7KdD"
   },
   "outputs": [],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "xgb_cv_results = make_results('XGB cv', xgb_cv, 'recall')\n",
    "results = pd.concat([results, xgb_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5IRnMO27KdD"
   },
   "source": [
    "This model fit the data even better than the random forest model. The recall score is nearly double the recall score from the logistic regression model from the previous course, and it's almost 50% better than the random forest model's recall score, while maintaining a similar accuracy and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfX0SjJffkh1"
   },
   "source": [
    "### **Task 11. Model selection**\n",
    "\n",
    "Now, use the best random forest model and the best XGBoost model to predict on the validation data. Whichever performs better will be selected as the champion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chgR3Tx8fn1s"
   },
   "source": [
    "#### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DUswawM2fyAf"
   },
   "outputs": [],
   "source": [
    "# Use random forest model to predict on validation data\n",
    "rf_val_preds = rf_cv.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz1eb4rqf11Z"
   },
   "source": [
    "Use the `get_test_scores()` function to generate a table of scores from the predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AJ9mCl0Uf4P4"
   },
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "        model_name (string): Your choice: how the model will be named in the output table\n",
    "        preds: numpy array of test predictions\n",
    "        y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "        table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'precision': [precision],\n",
    "                          'recall': [recall],\n",
    "                          'F1': [f1],\n",
    "                          'accuracy': [accuracy]\n",
    "                          })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "22ANR4ZHf5NK"
   },
   "outputs": [],
   "source": [
    "# Get validation scores for RF model\n",
    "rf_val_scores = get_test_scores('RF val', rf_val_preds, y_val)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, rf_val_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDeuk16igBD0"
   },
   "source": [
    "Notice that the scores went down from the training scores across all metrics, but only by very little. This means that the model did not overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8h2s5RpgEER"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    "Now, do the same thing to get the performance scores of the XGBoost model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "mQoTuRkngHjp"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on validation data\n",
    "xgb_val_preds = xgb_cv.best_estimator_.predict(X_val)\n",
    "\n",
    "# Get validation scores for XGBoost model\n",
    "xgb_val_scores = get_test_scores('XGB val', xgb_val_preds, y_val)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, xgb_val_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GspkQqUNgIm3"
   },
   "source": [
    "Just like with the random forest model, the XGBoost model's validation scores were lower, but only very slightly. It is still the clear champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HGsWfEOeWPm"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOm4n_1OgUND"
   },
   "source": [
    "### **Task 12. Use champion model to predict on test data**\n",
    "\n",
    "Now, use the champion model to predict on the test dataset. This is to give a final indication of how you should expect the model to perform on new future data, should you decide to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7BkheTIsgU2b"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on test data\n",
    "xgb_test_preds = xgb_cv.best_estimator_.predict(X_test)\n",
    "\n",
    "# Get test scores for XGBoost model\n",
    "xgb_test_scores = get_test_scores('XGB test', xgb_test_preds, y_test)\n",
    "\n",
    "# Append to the results table\n",
    "results = pd.concat([results, xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8L_LyIbgV1I"
   },
   "source": [
    "The recall was exactly the same as it was on the validation data, but the precision declined notably, which caused all of the other scores to drop slightly. Nonetheless, this is stil within the acceptable range for performance discrepancy between validation and test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5GNoz_QgWug"
   },
   "source": [
    "### **Task 13. Confusion matrix**\n",
    "\n",
    "Plot a confusion matrix of the champion model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WF3KErX8gXPc"
   },
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "cm = confusion_matrix(y_test, xgb_test_preds, labels=xgb_cv.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['retained', 'churned'])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xL4OujkgYC3"
   },
   "source": [
    "The model predicted three times as many false negatives than it did false positives, and it correctly identified only 16.6% of the users who actually churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P33INGPmgY1o"
   },
   "source": [
    "### **Task 14. Feature importance**\n",
    "\n",
    "Use the `plot_importance` function to inspect the most important features of your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "N4fc2i8XgZoE"
   },
   "outputs": [],
   "source": [
    "plot_importance(xgb_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU3GIZNrga5z"
   },
   "source": [
    "The XGBoost model made more use of many of the features than did the logistic regression model from the previous course, which weighted a single feature (`activity_days`) very heavily in its final prediction.\n",
    "\n",
    "If anything, this underscores the importance of feature engineering. Notice that engineered features accounted for six of the top 10 features (and three of the top five). Feature engineering is often one of the best and easiest ways to boost model performance.\n",
    "\n",
    "Also, note that the important features in one model might not be the same as the important features in another model. That's why you shouldn't discount features as unimportant without thoroughly examining them and understanding their relationship with the dependent variable, if possible. These discrepancies between features selected by models are typically caused by complex feature interactions.\n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion.\n",
    "\n",
    "Even if you cannot use the model to make strong predictions, was the work done in vain? What insights can you report back to stakeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 15. Conclusion**\n",
    "\n",
    "Now that you've built and tested your machine learning models, the next step is to share your findings with the Waze leadership team. Consider the following questions as you prepare to write your executive summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Would you recommend using this model for churn prediction? Why or why not?\n",
    "\n",
    "2. What tradeoff was made by splitting the data into training, validation, and test sets as opposed to just training and test sets?\n",
    "\n",
    "3. What is the benefit of using a logistic regression model over an ensemble of tree-based models (like random forest or XGBoost) for classification tasks?\n",
    "\n",
    "4. What is the benefit of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks?\n",
    "\n",
    "5. What could you do to improve this model?\n",
    "\n",
    "6. What additional features would you like to have to help improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NrXTUydBady"
   },
   "source": [
    "1. The model has too low of a recall score to make it a strong enough predictor.\n",
    "2. There was less data to train the model but the validation data will give the model a better esitmate of future preformance. \n",
    "3. The logistic regression models will tell you which features factored most heavily into the predictions.\n",
    "4. They require much less data cleaning and are typically better predictors.\n",
    "5. Try to produce, drop or transform some of the variables.\n",
    "6. It would be helpful to have drive-level information for each user (such as drive times, geographic locations, etc.). It would probably also be helpful to have more granular data to know how users interact with the app. For example, how often do they report or confirm road hazard alerts? Finally, it could be helpful to know the monthly count of unique starting and ending locations each driver inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij_DDQ2xSwyD"
   },
   "source": [
    "### **BONUS**\n",
    "\n",
    "The following content is not required, but demonstrates further steps that you might take to tailor your model to your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cw4qgviwSwXK"
   },
   "source": [
    "#### **Identify an optimal decision threshold**\n",
    "\n",
    "The default decision threshold for most implementations of classification algorithms&mdash;including scikit-learn's&mdash;is 0.5. This means that, in the case of the Waze models, if they predicted that a given user had a 50% probability or greater of churning, then that user was assigned a predicted value of `1`&mdash;the user was predicted to churn.\n",
    "\n",
    "With imbalanced datasets where the response class is a minority, this threshold might not be ideal. You learned that a precision-recall curve can help to visualize the trade-off between your model's precision and recall.\n",
    "\n",
    "Here's the precision-recall curve for the XGBoost champion model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "kVgiwBWtSxq4"
   },
   "outputs": [],
   "source": [
    "# Plot precision-recall curve\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    xgb_cv.best_estimator_, X_test, y_test, name='XGBoost'\n",
    "    )\n",
    "plt.title('Precision-recall curve, XGBoost model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxyauTCNSyND"
   },
   "source": [
    "As recall increases, precision decreases. But what if you determined that false positives aren't much of a problem? For example, in the case of this Waze project, a false positive could just mean that a user who will not actually churn gets an email and a banner notification on their phone. It's very low risk.\n",
    "\n",
    "So, what if instead of using the default 0.5 decision threshold of the model, you used a lower threshold?\n",
    "\n",
    "Here's an example where the threshold is set to 0.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "iiKAYfRwS1bW"
   },
   "outputs": [],
   "source": [
    "# Get predicted probabilities on the test data\n",
    "predicted_probabilities = xgb_cv.best_estimator_.predict_proba(X_test)\n",
    "predicted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4sLUzxFTcP9"
   },
   "source": [
    "The `predict_proba()` method returns a 2-D array of probabilities where each row represents a user. The first number in the row is the probability of belonging to the negative class, the second number in the row is the probability of belonging to the positive class. (Notice that the two numbers in each row are complimentary to each other and sum to one.)\n",
    "\n",
    "You can generate new predictions based on this array of probabilities by changing the decision threshold for what is considered a positive response. For example, the following code converts the predicted probabilities to {0, 1} predictions with a threshold of 0.4. In other words, any users who have a value ≥ 0.4 in the second column will get assigned a prediction of `1`, indicating that they churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ynzlIds4S1xi"
   },
   "outputs": [],
   "source": [
    "# Create a list of just the second column values (probability of target)\n",
    "probs = [x[1] for x in predicted_probabilities]\n",
    "\n",
    "# Create an array of new predictions that assigns a 1 to any value >= 0.4\n",
    "new_preds = np.array([1 if x >= 0.4 else 0 for x in probs])\n",
    "new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pYAKZbeqS5Vr"
   },
   "outputs": [],
   "source": [
    "# Get evaluation metrics for when the threshold is 0.4\n",
    "get_test_scores('XGB, threshold = 0.4', new_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z91aOpXQS51a"
   },
   "source": [
    "Compare these numbers with the results from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "i-tsYPiJTzdn"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_Hl_g6rTz5o"
   },
   "source": [
    "Recall and F1 score increased significantly, while precision and accuracy decreased.\n",
    "\n",
    "So, using the precision-recall curve as a guide, suppose you knew that you'd be satisfied if the model had a recall score of 0.5 and you were willing to accept the \\~30% precision score that comes with it. In other words, you'd be happy if the model successfully identified half of the people who will actually churn, even if it means that when the model says someone will churn, it's only correct about 30% of the time.\n",
    "\n",
    "What threshold will yield this result? There are a number of ways to determine this. Here's one way that uses a function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ahSvceazUsnP"
   },
   "outputs": [],
   "source": [
    "def threshold_finder(y_test_data, probabilities, desired_recall):\n",
    "    '''\n",
    "    Find the threshold that most closely yields a desired recall score.\n",
    "\n",
    "    Inputs:\n",
    "        y_test_data: Array of true y values\n",
    "        probabilities: The results of the `predict_proba()` model method\n",
    "        desired_recall: The recall that you want the model to have\n",
    "\n",
    "    Outputs:\n",
    "        threshold: The threshold that most closely yields the desired recall\n",
    "        recall: The exact recall score associated with `threshold`\n",
    "    '''\n",
    "    probs = [x[1] for x in probabilities]  # Isolate second column of `probabilities`\n",
    "    thresholds = np.arange(0, 1, 0.001)    # Set a grid of 1,000 thresholds to test\n",
    "\n",
    "    scores = []\n",
    "    for threshold in thresholds:\n",
    "        # Create a new array of {0, 1} predictions based on new threshold\n",
    "        preds = np.array([1 if x >= threshold else 0 for x in probs])\n",
    "        # Calculate recall score for that threshold\n",
    "        recall = recall_score(y_test_data, preds)\n",
    "        # Append the threshold and its corresponding recall score as a tuple to `scores`\n",
    "        scores.append((threshold, recall))\n",
    "\n",
    "    distances = []\n",
    "    for idx, score in enumerate(scores):\n",
    "        # Calculate how close each actual score is to the desired score\n",
    "        distance = abs(score[1] - desired_recall)\n",
    "        # Append the (index#, distance) tuple to `distances`\n",
    "        distances.append((idx, distance))\n",
    "\n",
    "    # Sort `distances` by the second value in each of its tuples (least to greatest)\n",
    "    sorted_distances = sorted(distances, key=lambda x: x[1], reverse=False)\n",
    "    # Identify the tuple with the actual recall closest to desired recall\n",
    "    best = sorted_distances[0]\n",
    "    # Isolate the index of the threshold with the closest recall score\n",
    "    best_idx = best[0]\n",
    "    # Retrieve the threshold and actual recall score closest to desired recall\n",
    "    threshold, recall = scores[best_idx]\n",
    "\n",
    "    return threshold, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13WcPXrEUgHx"
   },
   "source": [
    "Now, test the function to find the threshold that results in a recall score closest to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rVlW592vT_kT"
   },
   "outputs": [],
   "source": [
    "# Get the predicted probabilities from the champion model\n",
    "probabilities = xgb_cv.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "# Call the function\n",
    "threshold_finder(y_test, probabilities, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZkp1FY3Uw22"
   },
   "source": [
    "Setting a threshold of 0.124 will result in a recall of 0.503.\n",
    "\n",
    "To verify, you can repeat the steps performed earlier to get the other evaluation metrics for when the model has a threshold of 0.124. Based on the precision-recall curve, a 0.5 recall score should have a precision of \\~0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2PuIr8byUx8y"
   },
   "outputs": [],
   "source": [
    "# Create an array of new predictions that assigns a 1 to any value >= 0.124\n",
    "probs = [x[1] for x in probabilities]\n",
    "new_preds = np.array([1 if x >= 0.124 else 0 for x in probs])\n",
    "\n",
    "# Get evaluation metrics for when the threshold is 0.124\n",
    "get_test_scores('XGB, threshold = 0.124', new_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUvjKSSJVDMH"
   },
   "source": [
    "It worked! Hopefully now you understand that changing the decision threshold is another tool that can help you achieve useful results from your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1DHsmIEwaXUmfVT4tFzyOwyyfXAX0v6IF",
     "timestamp": 1675262571681
    },
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1674856595373
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
